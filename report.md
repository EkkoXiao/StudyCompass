# StudyCompass—私人个性化学习助手应用项目结题报告

## 引言

### 项目背景

学生群体面临课业压力，临近考试周时**上课课件**往往成为最为重要甚至唯一的复习资料。但课件**偏线性的知识内容交互模式**并不简易明晰，且其通过大量文本或图像信息呈现的**被动学习方式**往往存在**信息过载**，**缺少互动**等一系列问题，使用起来并不方便；同时，部分课程课件信息过于**简短精炼**，学生可能**需要额外资源**来进行深入理解，影响了复习效率。

另外，学生在使用课件学习时，首先需要在希望学习某一项知识点时能够在某门课程课件中进行**快速定位**，基于 Ctrl+F 的**全文搜索**极其依赖文本质量，容易出现**上下文缺失**与**关键词多义性**的问题，迫切需要具有总结概括能力与课件内容相结合的**直观迅捷定位模式**；在课件学习过程中**遇到疑难问题**时，也常常需要借助搜索引擎等获取答复，更需要在围绕整份课件展开的同时又能够侧重于当前学习的知识点内容**进行对话的定制功能**。

在当今数字化的学习环境中，**大语言模型**为学习助手应用提供了前所未有的机会；通过对自然语言的理解和生成，以及广泛的知识和学科背景，能够打破传统基于课件数字学习模式的局限，有效地定位、整理并传递知识点，为用户提供**更高效、深入的交互式学习体验**，为学习助手应用领域注入新的生机。

### 项目目标

- 支持导入 **PPTX，PDF，DOCX** 三种格式的课程文件，将相同课程的文件**归纳为资料库**，通过大语言模型提炼出课件文档**主要的知识点与其包含的子知识点**信息，并能够即时**映射到相应文档具体页码**，提供**迅捷定位**功能，提高需要进行知识点回顾时的学习效率；
- 对于单个知识点信息以课件内容为主，生成**图形化的知识信息概述页面**，便于对知识点信息的**快速掌握**，与课件并行使用时能够使用户第一时间获取当前内容的上下文知识点，解决课件上下文缺失的问题；同时通过**联网搜索**对相关信息展开拓展，生成拥有资料内容的相关链接，供进一步学习使用；
- 从多个维度衡量某个知识点信息的**知识密度**，确定知识点在学习过程中的权重，筛选权重较高的知识点构建基于整个资料库以及单份课件文件的**思维导图**，并在图中体现权重的差异，一改课件线性学习模式为**树状结构的图谱式学习**，**层次分明**，将知识点之间的重要性**可视化为节点大小**，一览无余；
- 在阅读器中能够支持针对当前文档已经阅读到的所在页上下文**开展实时问答**，提高用户学习过程中的**参与感**，同时使得问答功能语境**更加侧重于当前文件**而非大语言模型笼统的专业知识，提供**个性化**的对话功能。

项目目标整理如下图：

![](image.png)

### 使用方法

本项目为桌面应用程序开发项目，前端与后端均使用 Python 实现，通过持久化存储进行通信；针对上述四项项目目标，方法实现步骤阐述依次如下：

- 后端调用针对不同类型文件的解析相关库提取出文件对应到页的元信息；使用元信息访问大语言模型，给出合适的 Prompt，生成文档主知识点及其包含的子知识点信息，并将格式整理为 Json；前端调用 GUI 库生成知识点树状结构，使用新增文件接口将文件通过资料库规范化管理；
- 后端根据知识点名称及对应页相关文本，通过大语言模型生成子知识点简要介绍的 HTML 页面；调用联网搜索开源项目镜像，生成与当前知识点相关链接；前端将信息概述页面与树形结构中的知识点绑定；
- 后端根据探索确定相关的知识密度衡量公式，应用于每一个子知识点；根据子知识点知识密度进行归一化处理，从而逐层计算整张思维导图结点的知识密度；根据知识密度筛选出重要知识点，用于思维导图构建，避免主图过于繁琐；前端根据知识密度确定不同结点显示时的权重（半径），突出知识点重要性差异；
- 前端通过 GUI 库实现 PDF 阅读与知识点学习同步；通过点击回调实现从思维导图到 PDF 阅读器和知识点查看器的超链接；设计问答窗口，在确定文件与页数时进行异步问答并显示结果，同个会话支持类似 ChatGPT 的会话上下文同步。

具体实现相关细节参见系统设计与实现。

### 项目贡献

本项目首次推出主要面向学生课程学习的大语言模型主导知识图谱构建、同步阅读、实时对话三位一体的学习助手，解决目前市面上学习助手应用相关开源项目功能单一或冗余，没有兼顾知识点定位与实时答疑等重要用户需求的问题。本项目产品能够使用户全面纵览课件概况，快速定位知识要点，多维掌握资料信息，实时获取疑难答复，在数字化时代的人机交互中寓学于乐，高效学习。

## 后端系统设计：

### 后端功能简介：

本项目的后端主要工作为：提取用户提供的 PPTX，PDF，DOCX 文件中的内容，借助大语言模型的能力进行知识点的提取和总结，然后将知识点的信息生成 HTML 网页，并衡量这些知识点的知识密度，以 Json 格式将思维导图的树状结构知识点信息交由前端，从而生成一个主次分明的思维导图。同时，后端还支持联网搜索拓展知识点和实时知识问答，以帮助用户及时解决自己阅读文件时遇到的问题。

### 后端工作流程：

后端的工作流程可以总结为以下步骤：
1. 建立资料库，如果已有资料库则不再新建 
2. 添加目标文件 
3. 解析并储存文件内容（包括文字、图片、表格等多种形式的内容）
4. 提取文件关键词（用于概括文件的主题）
5. 提取主知识点（约5-10个，用于总括文件的主要内容）
6. 为每个主知识点生成子知识点（每个主知识点约3-5个，用于更加详细地描述主知识点）
7. 进行子知识点内容扩充和联网知识拓展（包括计算子知识点的知识密度，为每个子知识点生成 HTML 网页，联网搜索知识扩展等） 
8. 更新资料库的主思维导图（添加新文件的分支，并更新主思维导图的节点大小。根节点为知识库名称，次级节点为每个文件关键词，叶节点为主知识点）
9. 建立该文件的思维导图（根节点为关键词，次级节点为主知识点，叶节点为子知识点） 
10. 将该文件接入知识问答框架中，便于用户基于文件内容进行实时问答。

流程图如下：

!["后端流程图"](1.png)

### 后端框架优势：

1. 易于扩展：后端系统可以方便地添加新的功能模块，以满足不断变化的需求。
2. 所有对于文件的操作都是在后台异步执行的，不会影响用户在前端的正常使用。
3. 对于文件内容、生成的主知识点、子知识点都进行实时存储，方便在出现系统或者网络问题时及时进行回溯，而不需要从头开始生成。
   
## 后端系统实现：

### 建立资料库并添加文件

```py
def bCreateDatabase(db: str) :
```

使用 `bCreateDatabase` 创建资料库，确保有一个专门的工作区域用于进行该资料库相关的操作；利用 `bAddFiles` 将新的文件以流水线的形式添加到资料库中，用于后续操作的进行。

### 解析储存文件内容

```py
def metadata_extractor(db, file_path, id):
```

利用 `metadata_extractor` 函数解析和储存我们文件中的主要内容。由于像 PPTX 和 PDF 这种文件会存在图片和表格的特殊形式的内容，且有些关键知识点可能就在图片或表格中，直接丢弃并不合理，因此我们利用 `langchain`。`pptx`、`fitz` 等库来对文件信息进行尽可能全面的读取，并将所有数据按照形如（所在页数，数据类型，内容）的元组形式进行储存，并将图片提取出来单独储存，既保证提取数据的完整性，也方便后续进行知识拓展等操作。

## 提取关键词

```py
def keyword_generator(db, id):
```

利用 `keyword_generator` 函数概括并储存文件的关键词，将文件信息传递给大语言模型，通过对其生成格式和内容做出限制，就能够快速得到概括文件主要信息的关键词，将得到的关键词储存在资料库中以方便后续取用。

## 提取主知识点

```py
def mainpoints_generator(db, id):
```

使用 `mainpoints_generator` 函数，借助大语言模型根据每一页具体内容对文件进行分割，并用一句话简短总结每个部分的主要内容，将分割和总结后的知识点作为文件的主知识点。大语言模型会依据文件具体内容生成 5-10 个不等的主知识点，生成完成后将主知识点和其对应的页面数储存到资料库中。

## 生成子知识点

```py
def subpoints_generator(db, id):
```

利用 `subpoints_generator` 函数生成和总结文件每个主知识点的子知识点，通过遍历每一个主知识点和该知识点对应的页码，根据这些文件内容来提炼出 3-5 个不等的子知识点，子知识点是对主知识点某个方面的具体描述，并存储多角度的详细介绍，以便读者更好地进行理解。

## 对子知识点进行联网知识拓展 

```py
def subpoints_extension(db, id):
```

为了进一步丰富子知识点的信息，让用户能够不拘泥于给定文件，对该知识点有更加深入和全面的理解，我们利用 `openserp` 这一第三方库对所有子知识点进行了联网拓展，以获取更加丰富的知识信息。同时，为了保证知识拓展获取到的信息的有效性，同时借助大语言模型最新联网搜索功能对得到的 URL 路径进行筛选，只保留最有可能对用户有帮助的 5 个链接，极大地减小了知识过于繁杂或是良莠不齐的可能性，提升了用户的使用体验。功能具体实现在 `subpoints_extension` 函数中。

## 为子知识点生成 HTML 网页简介

```python
def html_generator(file_path, file_name, save_path):
```

为了让用户在前端能看到格式更加规范的知识点信息，`html_generator` 负责对生成的子知识点信息进行汇总和整理，以保证用户在每个页面都能看到对应的子知识点信息，而不用去手动查阅。在实现中提前指定了 HTML 网页的格式，在展示时只需填入目前获取到的所有子知识点信息，并将生成的 HTML 文件储存在资料库对应工作目录下即可。

## 计算知识点的知识密度

```py
def knowledge_density(db, id):
```

一般来说，文件中的知识点有主次之分，且用户在绝大部分情况下并不愿意花费太多时间在那些“正确的废话”上。为此，我们创造性地提出了知识密度的概念，用知识密度来衡量一个知识点中所包含的有用信息的密度，并在展示思维导图时给予那些知识密度比较高的点更高的比重，这也方便用户投入更多时间和精力在那些比较重要的知识点上，提升了学习效率。

下为知识密度的计算公式：

\[ W = (\alpha \times \frac{N_k}{N_t}) + (\beta \times \frac{P_k}{P_t}) + \left( \gamma \times \sum_{i=1}^{m-1} \sum_{j=i+1}^{m} \sqrt{\sum_{k=1}^{n} (v_{ik} - v_{jk})^2} \right) + (\delta \times D_g) \]

- \( W \) 是知识密度（weight）。
- \( \alpha, \beta, \gamma, \delta \) 是自定义系数，用于控制每项参数在最后的知识密度计算中所占的比重，这里定为\( \alpha = 4, \beta = 2.5, \gamma = 1 , \delta = 0.5 \)。
- \( N_k \) 是知识点字数。
- \( N_t \) 是总字数。
- \( P_k \) 是知识点页数。
- \( P_t \) 是总页数。
- \( D_e \) 是知识点内部各个字的欧几里得距离之和，表示为：
  \[ D_e = \sum_{i=1}^{m-1} \sum_{j=i+1}^{m} \sqrt{\sum_{k=1}^{n} (v_{ik} - v_{jk})^2} \]
  其中，\( v_{ik} \) 和 \( v_{jk} \) 是知识点中第 \( i \) 和第 \( j \) 个字在第 \( k \) 维的分量。
  在实现时，我们先对传入的语句进行分词，再利用网络上的中文 word2vector 模型将分词后的语料转化为向量，最后计算各向量之间的欧几里得距离，得到对这些文字信息密度的衡量结果。
- \( D_g \) 是大语言模型基于自己对该领域的了解所给出的对于给定语料的知识密度的评估值（取值在 1-5 之间）。

在具体实现时，为了更好地反映出节点之间信息密度的相对大小，便于用户在遍历知识点时有所取舍，我们还引入了“相对知识密度”的概念，用一个0到1之间的值来衡量在该文件的所有知识点中，当前知识点的相对知识含量，进一步优化了用户的体验。该部分具体实现在`knowledge_density` 函数中。

## 更新资料库的主思维导图节点

```py
def generate_main_graph(db, colors):
```

在加入新的文件后，我们还要对资料库的主思维导图进行更新。由于思维导图需要尽可能简练且清晰，我们对每个文件的主知识点进行了“缩点”处理。所谓“缩点”即为每个文件提取知识密度最大的前五个知识点，并将这些知识点的描述尽可能简化，以便于图形化展示。同时，我们还对思维导图的同一子树进行相近色系的着色，让用户能更直观地了解不同知识点之间的相关性；该部分具体实现在 `generate_main_graph` 函数中。

## 新建该文件的思维导图节点 

```py
def generate_file_graph(db, id, colors):
```

和之前的主思维导图类似，在新加入一个文件时，我们还要对该文件新建思维导图，以方便用户更快地厘清文件的框架。我们同样对文件的主知识点和子知识点进行“缩点”处理，所有的操作和主思维导图节点完全一致，该部分具体实现在 `generate_file_graph` 函数中。

## 实时知识问答

```py
def bConversation(db: str, context) :
```

为了进一步优化用户体验，让用户能够更加便捷地解决自己的疑问，我们还添加了实时知识问答功能，相较于直接询问 ChatGPT 等大语言模型，我们的知识问答框架不仅能将文件内容全部提供给大模型，还能够依据用户当前正在翻看的文件页码为大模型提供更加有针对性的引导，从而让大模型可以依据于文件内容给出更加专业且有针对性的回答，而不至于“答非所问”或者“一本正经地胡说八道”，这也极大地改善了用户的使用体验。该部分具体实现在 `bConversation` 函数中。

## 前端系统设计

### 前端功能简介

前端负责将后端提供的树形结构数据进行可视化呈现，绘制简单明晰的思维导图，能够在点击思维导图的同时迅捷定位到目标知识点所在文件上下文；支持课件阅读，知识点信息概览页阅读，知识图谱梳理与实时对话功能页的同步呈现，允许用户自由选择窗口的布局、只展示自己所需要的内容，实现定制化交互式的学习模式。

### 前端工作流程

前端的工作流程可以总结为以下步骤：
1. 选择左侧资料库，进行所需学习课程内容的初步浏览，通过库思维导图或左侧文件树结构选择所需学习的目标课件；
   ![image-20240122184803153](https://s2.loli.net/2024/01/22/ImF6jSVoYdhuEDM.png)
2. 浏览目标课件的知识结构图，相较库思维导图更加精细，通过点击图上节点定位到相关文件页上下文；
   ![image-20240122202408232](https://s2.loli.net/2024/01/22/jse1v6oWQnK5pu2.png)
3. 知识点和 PDF 支持同步阅读，PDF翻页时，知识点阅读器也会自动翻页。相关的链接也可以直接点击；
   ![image-20240122203943458](https://s2.loli.net/2024/01/22/bSJFkE7v1YRuard.png)
4. 在相关页上下文能够开展与大模型的对话，使其能够获取到当前正在阅读的课件及其具体页数，从而获得更加针对性的回答；
   ![](dialogs.png)

### 前端框架优势

1. 将知识库-文件-主知识点-子知识点组织成了树状结构，并使用有明显颜色和特征的图案区分，易于用户理解和查找；常用的功能性的按钮如“添加文件”等也被整合到了树中，简化用户操作；
2. 仿照浏览器标签页制作功能界面，各种功能界面间切换极其容易，文件阅读器、知识点阅读器等还会同步切换，保证知识点和文件永远对应相同语境；
3. 使用“使用新窗口打开当前标签页”按钮能够将标签页脱离主窗口，使之成为独立且可自由调整大小和位置的窗口，避免在同一个窗口同时显示大量内容。
4. 实时对话功能相应受限于网络条件可能较慢，但采取异步方式能够在对话过程中进行其他操作，提升用户友好性。

## 前端系统实现

前端使用 `python` GUI 库 `tkinter`，通过继承基础控件实现多种操作的支持，同时使用 `tkhtmlview` 库实现文件的实时阅读以及翻页操作，通过 `networkx` 库以及其他一系列辅助库完成知识图谱的绘制，同时能够支持节点的拖拽与定义。

## 项目评估

本项目在完成之后开展了用户实验进行评估，所受到的相关反馈如下：

用户 A：目前市面上绝大部分学习助手功能较为冗余（暴论），本项目产品能够从学生群体实际情况入手，产品功能针对性较强；但学生群体可能更加需求出题与题解功能，现有的大语言模型接口实现起来并非易事；
用户 B：项目实现新颖，符合大学生的实际需求；现有实现的 UI 还可以进行一些美化和改善；
用户 C：用知识图谱进行交互式学习、以及对话功能都挺有意思，但使用大语言模型进行知识点总结详细看来效果不太稳定。

总体来说，本项目较好实现了项目指定的目标，解决了相应的用户需求，但也存在相应需要改善和拓展提升之处。

## 未来展望

1. 继续拓展用户需求度较高的项目功能，主要包括提供出题与题解（使用大语言模型与联网搜索结合实现，需要从专业置信度高得网站上爬取）、制定学习计划与时间分配（结合先前提到得知识密度进行学习时间的衡量）、定时提醒复习（需要结合艾宾浩斯遗忘曲线等进行衡量）等等。
2. 解决大语言模型知识点总结上效果不稳定的问题，可以通过针对不同形式课件进行多模型融合设计，人工对课件知识点进行标注并引入奖惩机制训练特定领域的语言模型，或是使用更先进的自监督模型等（超出课程项目要求的范畴）；
3. 优化交互界面 UI 设计，尝试使用前后端分离的开发模式进行网页开发部署等。